{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feat_viz_resnet34_part_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "I9VDrPCrR1__",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Finding feature maps that are maximally activated by a specific image\n",
        "## Network used: ResNet-34"
      ]
    },
    {
      "metadata": {
        "id": "39Ch5JJ-lJSI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M8ylYU0BO9QP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q fastai==0.7.0 torchtext==0.2.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q1w2HnvvlP2z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.conv_learner import *\n",
        "from cv2 import resize\n",
        "import matplotlib.gridspec as gridspec\n",
        "from math import ceil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7bBwWLBhha2Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pdb import set_trace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5YpDdNpkVTCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from scipy import ndimage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UQ2d_EVYBODD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SaveFeatures():\n",
        "    def __init__(self, module):\n",
        "        self.hook = module.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.features = output\n",
        "    def close(self):\n",
        "        self.hook.remove()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OFxPmIboP5c_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FilterVisualizer():\n",
        "    def __init__(self):\n",
        "        self.model = nn.Sequential(*list(resnet34(True).children())[:-2]).cuda().eval()\n",
        "        set_trainable(self.model, False)\n",
        "\n",
        "    def visualize(self, sz, layer, filter, upscaling_steps=12, upscaling_factor=1.2, lr=0.1, opt_steps=20, blur=None, save=False, print_losses=False):\n",
        "\n",
        "        img = (np.random.random((sz, sz, 3)) * 20 + 128.)/255.\n",
        "#         img = np.random.uniform(0, 1, size=(sz, sz, 3)).astype(np.float32)\n",
        "#         median_filter_size = 4 if sz < 100 else 8\n",
        "#         img = scipy.ndimage.filters.median_filter(img, [median_filter_size,median_filter_size,1])\n",
        "\n",
        "        activations = SaveFeatures(layer)  # register hook\n",
        "\n",
        "        for i in range(upscaling_steps):  # scale the image up upscaling_steps times\n",
        "            train_tfms, val_tfms = tfms_from_model(resnet34, sz)\n",
        "            img_var = V(val_tfms(img)[None], requires_grad=True)  # convert image to Variable that requires grad\n",
        "            optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
        "            if i > upscaling_steps/2:\n",
        "                opt_steps_ = int(opt_steps*1.3)\n",
        "            else:\n",
        "                opt_steps_ = opt_steps\n",
        "            for n in range(opt_steps_):  # optimize pixel values for opt_steps times\n",
        "                optimizer.zero_grad()\n",
        "                self.model(img_var)\n",
        "                loss = -1*activations.features[0, filter].mean()\n",
        "                if print_losses:\n",
        "                    if i%3==0 and n%5==0:\n",
        "                        print(f'{i} - {n} - {float(loss)}')\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            img = val_tfms.denorm(np.rollaxis(to_np(img_var.data),1,4))[0]\n",
        "            self.output = img\n",
        "            sz = int(upscaling_factor * sz)  # calculate new image size\n",
        "            img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
        "            if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
        "        activations.close()\n",
        "        return np.clip(self.output, 0, 1)\n",
        "    \n",
        "    def get_transformed_img(self,img,sz):\n",
        "        train_tfms, val_tfms = tfms_from_model(resnet34, sz)\n",
        "        return val_tfms.denorm(np.rollaxis(to_np(val_tfms(img)[None]),1,4))[0]\n",
        "    \n",
        "    def most_activated(self, image, layer, limit_top=None):\n",
        "\n",
        "        train_tfms, val_tfms = tfms_from_model(resnet34, 224)\n",
        "        transformed = val_tfms(image)\n",
        "\n",
        "        activations = SaveFeatures(layer)  # register hook\n",
        "        self.model(V(transformed)[None]);\n",
        "        \n",
        "        mean_act = [activations.features[0,i].mean().data.cpu().numpy()[0] for i in range(activations.features.shape[1])]\n",
        "        activations.close()\n",
        "        return mean_act"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KGm5tqr2VinJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b1dd5557-cdba-4458-f0a2-292a551e9316"
      },
      "cell_type": "code",
      "source": [
        "FV = FilterVisualizer()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.torch/models/resnet34-333f7ec4.pth\n",
            "100%|██████████| 87306240/87306240 [00:00<00:00, 114877173.59it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DBT9Yd4bYIJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2335
        },
        "outputId": "2ffd4c58-ee55-43b6-d230-d3b56f738d35"
      },
      "cell_type": "code",
      "source": [
        "FV.model"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "  (2): ReLU(inplace)\n",
              "  (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "bjxLkmZk0nqb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BbTkEgE0pDi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('img_at.txt') as f:\n",
        "    ACCESS_TOKEN = f.read().strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lokp5dZ43hjx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_from_url(url,file_name):\n",
        "    !wget -qq \"{url}\" -O {file_name}\n",
        "    return open_image(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDRV73IZ0qVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def upload_to_imgur(file_name,post_title,album_hash):\n",
        "    url = 'https://api.imgur.com/3/image'\n",
        "    fh = open(file_name, 'rb');\n",
        "    payload = {'image': base64.b64encode(fh.read()),\n",
        "              'album':album_hash,\n",
        "              'type':'base64',\n",
        "              'title':post_title,\n",
        "              'looping':False\n",
        "              }\n",
        "    files = {}\n",
        "    headers = {\n",
        "      'Authorization': f'Bearer {ACCESS_TOKEN}'\n",
        "    }\n",
        "    response = requests.request('POST', url, headers = headers, data = payload, files = files, allow_redirects=False)\n",
        "    return response.json()['data']['link']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uByz2aDB1i3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_imgur_album(title,description='',privacy='hidden'):\n",
        "    url = 'https://api.imgur.com/3/album'\n",
        "    payload = {\n",
        "        'title': title,\n",
        "        'description': description,\n",
        "        'privacy':privacy}\n",
        "    files = {}\n",
        "    headers = {\n",
        "      'Authorization': f'Bearer {ACCESS_TOKEN}'\n",
        "    }\n",
        "    response = requests.request('POST', url, headers = headers, data = payload, files = files, allow_redirects=False)\n",
        "    print(f\"https://imgur.com/a/{response.json()['data']['id']}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkaJSex927kd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plotting mean activations per feature map and corresponding input space"
      ]
    },
    {
      "metadata": {
        "id": "hBP4p6k5gf6-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_activations_and_reconstructions(imgs,activations,filters,\n",
        "                                         transformed_img,n_cols=3,\n",
        "                                         cell_size=4,layer_name='',\n",
        "                                         save_fig=False,album_hash=None):\n",
        "    n_rows = ceil((len(imgs)+1)/n_cols)\n",
        "\n",
        "    fig = plt.figure(figsize=(cell_size*n_cols,cell_size*n_rows))\n",
        "    gs = gridspec.GridSpec(n_rows, n_cols)\n",
        "    tr_im_ax = plt.subplot(gs[0,0])\n",
        "    tr_im_ax.grid(False)\n",
        "    tr_im_ax.get_xaxis().set_visible(False)\n",
        "    tr_im_ax.get_yaxis().set_visible(False)\n",
        "    tr_im_ax.imshow(transformed_img)\n",
        "    tr_im_ax.set_title('Image')\n",
        "    \n",
        "    act_ax = plt.subplot(gs[0, 1:])\n",
        "    \n",
        "    \n",
        "    act = act_ax.plot(np.clip(activations,0.,None),linewidth=2.)\n",
        "    for el in filters:\n",
        "        act_ax.axvline(x=el, color='red', linestyle='--',alpha=0.4)\n",
        "    act_ax.set_xlim(0,len(activations));\n",
        "    act_ax.set_ylabel(f\"mean activation\");\n",
        "    if layer_name == '':\n",
        "        act_ax.set_title('Mean Activations')\n",
        "    else:\n",
        "        act_ax.set_title(f'{layer_name}')\n",
        "    act_ax.set_facecolor('white')\n",
        "    \n",
        "    fmap_axes = []\n",
        "    for r in range(1,n_rows):\n",
        "        for c in range(n_cols):\n",
        "            fmap_axes.append(plt.subplot(gs[r, c]))\n",
        "            \n",
        "    for i,ax in enumerate(fmap_axes):\n",
        "        ax.grid(False)\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        if i>=len(filters):\n",
        "            pass\n",
        "\n",
        "        ax.set_title(f'fmap {filters[i]}')\n",
        "\n",
        "        ax.imshow(imgs[i])\n",
        "    plt.tight_layout()\n",
        "    save_name = layer_name.lower().replace(' ','_')\n",
        "    if save_fig:\n",
        "        plt.savefig(f'{save_name}.png')\n",
        "        upload_to_imgur(f'{save_name}.png',\n",
        "                        f'{save_name}',album_hash)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3d53GaBtRORh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def activations_and_reconstructions(img,activation_layer,fmap_layer,\n",
        "                                    top_num=4,init_size=56,\n",
        "                                    upscaling_steps=12, upscaling_factor=1.2,\n",
        "                                    opt_steps=20, blur=5,lr=1e-1,\n",
        "                                    print_losses=False,\n",
        "                                    n_cols=3, cell_size=4,\n",
        "                                    layer_name='',\n",
        "                                    save_fig=False,\n",
        "                                    album_hash=None):\n",
        "    \n",
        "    mean_acts = FV.most_activated(img,layer = activation_layer)\n",
        "\n",
        "    most_act_fmaps = sorted(range(len(mean_acts)), key=lambda i: mean_acts[i])[-top_num:][::-1]\n",
        "\n",
        "    imgs = []\n",
        "    for filter in most_act_fmaps:\n",
        "        imgs.append(FV.visualize(init_size,fmap_layer, filter, upscaling_steps=upscaling_steps, \n",
        "                                 upscaling_factor=upscaling_factor, \n",
        "                                 opt_steps=opt_steps, blur=blur,\n",
        "                                 lr=lr,print_losses=False))\n",
        "    transformed_img = FV.get_transformed_img(img,224)\n",
        "    \n",
        "    plot_activations_and_reconstructions(imgs,mean_acts,\n",
        "                                         most_act_fmaps,transformed_img,\n",
        "                                         n_cols=n_cols,cell_size=cell_size,\n",
        "                                         layer_name=layer_name,\n",
        "                                         save_fig=save_fig,\n",
        "                                         album_hash=album_hash)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlfVXhEF1Myx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_urls_1 = [\n",
        "    'https://pbs.twimg.com/profile_images/871470043200094209/1UAyRdei_400x400.jpg',\n",
        "    'http://farm3.static.flickr.com/2423/3957827131_90978df60b.jpg',\n",
        "    'http://farm1.static.flickr.com/97/209577710_344cf9b77d.jpg',\n",
        "    'http://farm1.static.flickr.com/232/500314013_56e18dd72e.jpg',\n",
        "    'http://farm4.static.flickr.com/3283/2536420364_2cbb96fb64.jpg',\n",
        "    'http://farm3.static.flickr.com/2418/1988187373_548be0682c.jpg',\n",
        "    'http://farm4.static.flickr.com/3195/2703096506_8963dac892.jpg',\n",
        "    'http://farm2.static.flickr.com/1093/883043423_8503b98702.jpg',\n",
        "    'http://farm4.static.flickr.com/3220/2659962123_a5d9d9f080.jpg',\n",
        "    'http://farm3.static.flickr.com/2420/2252055675_1ec3de9c46.jpg',\n",
        "    'http://farm4.static.flickr.com/3216/2416297192_b4ff2a87d8.jpg',\n",
        "    'http://farm4.static.flickr.com/3195/2690113895_507f0fb71a.jpg',\n",
        "    'http://farm4.static.flickr.com/3097/2476598462_f5a95c12e4.jpg',\n",
        "    'http://static.flickr.com/96/279601307_427e163e90_o.jpg',\n",
        "    'http://farm3.static.flickr.com/2155/2485884251_6e28c59fdd.jpg',\n",
        "    'http://farm4.static.flickr.com/3073/2820931609_3e5c8ceae2.jpg',\n",
        "    'http://farm1.static.flickr.com/134/325737039_2cb3de029e.jpg',\n",
        "    'http://farm3.static.flickr.com/2003/2047290079_c962beeb85.jpg',\n",
        "]\n",
        "              "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tr3pwaB81IU3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_urls_2 =[\n",
        "    'http://farm3.static.flickr.com/2672/3729197896_e2fcb07887.jpg',\n",
        "    'http://farm3.static.flickr.com/2419/2130941151_b100201751.jpg',\n",
        "    'http://farm3.static.flickr.com/2446/3570779025_4748186d3f.jpg',\n",
        "    'http://farm4.static.flickr.com/3504/3757435933_686e12d502.jpg',\n",
        "    'http://farm4.static.flickr.com/3198/2408009683_9eb72cd5d1.jpg',\n",
        "    'http://farm2.static.flickr.com/1389/1449509194_6b9a7f7003.jpg',\n",
        "    'http://farm4.static.flickr.com/3147/2905958970_cf47a19ece.jpg',\n",
        "    'http://farm4.static.flickr.com/3213/2845504219_4cd956bcf2.jpg',\n",
        "    'http://farm3.static.flickr.com/2099/2233817436_3f20abe7df.jpg',\n",
        "    'http://farm4.static.flickr.com/3176/2344377903_f5be963a37.jpg',\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpLGcUfg4uGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing for `ReLU` in blocks `5` and `6` of layer `3`, and blocks `1`, `2`, and `3` in layer `4`."
      ]
    },
    {
      "metadata": {
        "id": "WmhJY1gg1Urg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "urls = [image_urls_1,image_urls_2]\n",
        "hashes = ['N0dUcS0','i1IMVM6']\n",
        "\n",
        "for i in range(2):\n",
        "    album_hash = hashes[i]\n",
        "    for url in urls[i]:\n",
        "        try:\n",
        "            image = image_from_url(url,'dummy.jpg')\n",
        "\n",
        "            activations_and_reconstructions(image,children(FV.model)[6][4].relu,\n",
        "                                    children(FV.model)[6][4].relu,\n",
        "                                    top_num=6,layer_name='Resnet34 Layer3 Block5 Relu',\n",
        "                                            save_fig=True,album_hash=album_hash)\n",
        "\n",
        "            activations_and_reconstructions(image,children(FV.model)[6][5].relu,\n",
        "                                    children(FV.model)[6][5].relu,\n",
        "                                    top_num=6,layer_name='Resnet34 Layer3 Block6 Relu',\n",
        "                                            save_fig=True,album_hash=album_hash)\n",
        "\n",
        "            activations_and_reconstructions(image,children(FV.model)[7][0].relu,\n",
        "                                    children(FV.model)[7][0].relu,\n",
        "                                    top_num=6,layer_name='Resnet34 Layer4 Block1 Relu',\n",
        "                                            save_fig=True,album_hash=album_hash)\n",
        "\n",
        "            activations_and_reconstructions(image,children(FV.model)[7][1].relu,\n",
        "                                    children(FV.model)[7][1].relu,\n",
        "                                    top_num=6,layer_name='Resnet34 Layer4 Block2 Relu',\n",
        "                                            save_fig=True,album_hash=album_hash)\n",
        "\n",
        "            activations_and_reconstructions(image,children(FV.model)[7][2].relu,\n",
        "                                    children(FV.model)[7][2].relu,\n",
        "                                    top_num=6,layer_name='Resnet34 Layer4 Block3 Relu',\n",
        "                                            save_fig=True,album_hash=album_hash)\n",
        "        except Exception as e:\n",
        "            print(str(e))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CU7ooc0T1ZwX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "Plotting some of the results for feature maps in different layers."
      ]
    },
    {
      "metadata": {
        "id": "NZK7GSXI5gxQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/taKzea2.png)\n",
        "![](https://i.imgur.com/XtIcWcv.png)\n",
        "\n",
        "---\n",
        "\n",
        "![](https://i.imgur.com/yys2bSK.png)\n",
        "![](https://i.imgur.com/aLNMy3W.png)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "id": "VJ0xkRGt55JI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/o3D03T7.png)\n",
        "\n",
        "---\n",
        "\n",
        "![](https://i.imgur.com/E31wkk9.png)\n",
        "\n",
        "---\n",
        "\n",
        "![](https://i.imgur.com/7rvSiyb.png)\n",
        "\n",
        "---\n",
        "\n",
        "![](https://i.imgur.com/ZYqq8GK.png)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "id": "W4E-WEBa5_6k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/hrffqiK.png)\n",
        "![](https://i.imgur.com/rY00qbs.png)\n",
        "\n",
        "---\n",
        "\n",
        "![](https://i.imgur.com/CaoW2mG.png)\n",
        "![](https://i.imgur.com/c4hibxG.png)\n",
        "\n",
        "---\n",
        "\n",
        "![](https://i.imgur.com/vkzrHYh.png)\n",
        "![](https://i.imgur.com/DibmP8m.png)"
      ]
    },
    {
      "metadata": {
        "id": "IaIQaBOJ6I2C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All results can be seen [here](https://imgur.com/a/N0dUcS0) and [here](https://imgur.com/a/i1IMVM6)."
      ]
    }
  ]
}